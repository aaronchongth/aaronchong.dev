(window["webpackJsonp"]=window["webpackJsonp"]||[]).push([[2],{9593:function(e,t,n){"use strict";n.r(t);var a=function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("q-card",{staticClass:"q-pa-lg q-ma-sm col-12 col-lg-5",attrs:{flat:"",bordered:""}},[n("q-card-section",[n("div",{staticClass:"text-h6"},[e._v("\n      "+e._s(e.title)+"\n    ")]),n("div",{staticClass:"text-subtitle2 q-pt-xs"},[e._v("\n      "+e._s(e.source)+"\n    ")])]),n("img",{attrs:{src:e.resolve_img_url(e.img_name)}}),n("q-card-actions",[n("q-btn",{attrs:{color:"dark",round:"",flat:"",dense:"",icon:e.expanded?"keyboard_arrow_up":"keyboard_arrow_down"},on:{click:function(t){e.expanded=!e.expanded}}})],1),n("q-dialog",{model:{value:e.expanded,callback:function(t){e.expanded=t},expression:"expanded"}},[n("q-card",{staticStyle:{width:"800px","max-width":"80vw"}},[n("q-markdown",{staticClass:"q-ma-xl col",attrs:{src:e.markdown,toc:""},on:{data:e.onToc}})],1)],1)],1)},i=[],o={name:"project",props:{img_name:{type:String,required:!0},title:{type:String,required:!0},source:{type:String,required:!0},markdown:{type:String,required:!0}},data(){return{expanded:!1}},methods:{resolve_img_url:function(e){return"https://raw.githubusercontent.com/aaronchongth/quasar-site/assets/"+e}}},s=o,r=n("2877"),l=n("f09f"),c=n("a370"),d=n("4b7e"),m=n("9c40"),u=n("24e8"),h=n("eebe"),p=n.n(h),f=Object(r["a"])(s,a,i,!1,null,null,null);t["default"]=f.exports;p()(f,"components",{QCard:l["a"],QCardSection:c["a"],QCardActions:d["a"],QBtn:m["a"],QDialog:u["a"]})},eea6:function(e,t,n){"use strict";n.r(t);var a=function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("q-page",{staticClass:"flex page-container column col-12"},[n("div",{staticClass:"q-ma-lg q-pa-md row items-start justify-center q-gutter-md"},e._l(e.projects,(function(e){return n("project",{key:e.title,attrs:{img_name:e.img_name,title:e.title,source:e.source,markdown:e.markdown}})})),1)])},i=[],o="# VEGAN - Visual Enhancement Generative Adversarial Networks for Deblurring\n## 2018 - MRSD Class of 2018\n\n![](https://raw.githubusercontent.com/aaronchongth/quasar-site/assets/vegan.png)\n\nIn recent years deep learning has made great strides in performing various complex computer vision tasks (e.g. classification, segmentation, etc.). However, the world is imperfect and image classification networks often have to classify noisy images.\n\nOne form of noise is motion blur. Because the majority of these networks are trained and tested on carefully curated datasets which only contain clear, sharp images, the networks perform poorly on blurry images. If the blur in the images could be removed, then the networks could improve their accuracy.\n\nA classical strategy to deblur images is to select a deblurring kernel and then convolve the kernel across the image to restore it. Selecting the deblurring kernel is often a difficult and imprecise task. The optimal deblurring kernel is unique to the motion blur in the image, and selecting the wrong kernel produces inaccurate results. Kupyn et al. have recently presented DeblurGAN, which aims to solve this problem of motion blurred images through the use of a Generational Adversarial Network (GAN). In this project we will implement DeblurGAN and then adapt it to work with new datasets and validation methods.\n\nLink to full paper, https://raw.githubusercontent.com/son-of-a-gan/vegan-paper/master/ve-gan.pdf\n",s="# Driving Computer Vision with Deep Learning\n## 2018 - Internship at Wayve\n\n[Link to video](https://www.youtube.com/watch?v=SskSDjUG8ZY)\n\n![](https://raw.githubusercontent.com/aaronchongth/quasar-site/assets/perception.png)\n\nDuring my internship at Wayve, I was tasked to perform scene understanding in the form of depth, semantic segmentation and optical flow estimation onboard the vehicle's minimal compute, at real-time performance.\n\nFrom these requirements, the team and I used Nvidia's TensorRT libraries to further serialize and optimize the various neural networks required to run onboard, which would not fit all 3 models at the same time in normal circumstances. Inference speed was also great improved through the use of this library, allowing us to perform real-time estimation while the vehicle navigated through traffic, which allowed us to visualize how the vehicle could understand the world around it.\n\nI had an amazing summer with the team, and would like to thank them for all the lessons and support. Full blog post here, https://www.wayve.ai/blog/driving-computer-vision-with-deep-learning/\n",r="# Clearfield Robotics\n## 2017 - MRSD Class of 2018 \n\n[Link to video](https://www.youtube.com/watch?v=m2MoFOFM4Ng)\n\n![](https://raw.githubusercontent.com/aaronchongth/quasar-site/assets/clearfield_robotics.jpg)\n\nLandmines are a tragic remnant of war that the threaten economic security, mobility, and lives of people around the world. Though there has been a plethora of research in landmine sensing in the last few decades, most methods are expensive, energy-intensive, and result in a high number of false positives.\n\nClearField Robotics aims to improve outcomes in the field by reducing the time and cost of land surveying. By incorporating multi-modal sensing systems, we can reduce the need for singular, highly sensitive, and expensive equipment with sensor fusion. The goal of ClearField Robotics is to develop a low cost, user-friendly, and adoptable method of landmine detection without sacrificing accuracy. We combine a traditional metal detector (for broad sweeping) and an automated probing mechanism (to classify the shape of any detected metal objects) to reduce the number of false positives, increase demining speed, reduce demining costs.\n",l="# Variable Stiffness Spring Actuators for Low-Energy-Cost Human Augmentation\n## 2019 - IEEE Transactions on Robotics\n\n[Link to paper](https://ieeexplore.ieee.org/document/8833513)\n\n![](https://raw.githubusercontent.com/aaronchongth/quasar-site/assets/variable_stiffness.jpg)\n\nTheoretical studies suggest and experimental evidence confirms that maintaining and changing human joint stiffness by coactivated antagonistic muscles are metabolically expensive, even if muscles do not perform net mechanical work. Based on this observation, we posit that effective human augmentation can be achieved by actuators operated in parallel to human joints, even if these actuators only supplement joint stiffness without doing net mechanical work.\n\nIn this article, we present a prototype variable-length leaf-spring actuator capable of large-range stiffness modulation. The key feature of the actuator is that it provides intrinsically low-energy-cost stiffness modulation even for large output deflection, by keeping the force on the driving motor low. Variable stiffness actuators use two motors to provide both stiffness and equilibrium position modulation as they are designed to do net mechanical work. The proposed actuator conceptually differs from variable stiffness actuators because first, it uses a single motor to only provide stiffness modulation, second, it does not provide equilibrium position modulation, and third, unless externally loaded, it cannot do net mechanical work.\n\nUsing this actuator, we demonstrate stiffness augmentation during human-machine collaboration in challenging postural stabilization and weight-bearing tasks. Our results indicate that the proposed actuator can be used to complement a biological system by restoring or extending its functionality with low energy cost, and that variable stiffness spring actuators could effectively augment humans by doing no or a limited amount of mechanical work.\n",c="# Stiffness Modulator: A Novel Actuator for Human Augmentation\n## 2018 - IEEE ICRA\n\n[Link to paper](https://ieeexplore.ieee.org/document/8463186)\n\n![](https://raw.githubusercontent.com/aaronchongth/quasar-site/assets/stiffness_modulator.jpg)\n\nStiffness modulators are devices that promote a novel means of actuation; they provide stiffness modulation without deliberately doing mechanical work. These type of compliant actuators may be used for human augmentation to complement co-contracted antagonistic muscles and as such reduce muscle activity and metabolic energy cost.\n\nDespite the theoretical appeal of this concept, its implementation remains elusive in practical applications. This is particularly true for human augmentation which requires a portable stiffness modulator. In this paper, we present a compact, lightweight, and self-contained stiffness modulator. Using this device, we demonstrate stiffness augmentation of the human knee joint in a sit to stand task. The experimental results indicate that the proposed device is able to assist a human by reducing muscle activity while drawing minimal battery power.\n",d="# Analytical conditions for the design of variable stiffness mechanisms\n## 2017 - IEEE ICRA\n\n[Link to paper](https://ieeexplore.ieee.org/document/7989147)\n\n![](https://raw.githubusercontent.com/aaronchongth/quasar-site/assets/analytical_design.jpg)\n\nThis paper introduces an analytical approach for the design of variable stiffness mechanisms. The basis of this approach is a general model - representing the potential energy function and the physical constraints - covering the design space of variable stiffness mechanisms.\n\nUsing this model, we present a systematic procedure to analytically define classes of variable stiffness mechanisms from first principles. Consequently, we identify mechanisms capable of infinite range stiffness modulation using bounded motor forces, and define the simplest mathematical model representing mechanisms in this class. A prototype mechanism consistent with this canonical model is designed, fabricated and experimentally tested. The experimental data are consistent with our theoretical predictions showing constant motor force independent of the output deflection and output stiffness when the mechanism is subject to external load.\n",m={name:"home",components:{project:n("9593").default},data(){return{projects:[{img_name:"vegan.png",title:"VEGAN - Visual Enhancement Generative Adversarial Networks for Deblurring",source:"2018 - MRSD Class of 2018",markdown:o},{img_name:"perception.png",title:"Driving Computer Vision with Deep Learning",source:"2018 - Internship at Wayve",markdown:s},{img_name:"clearfield_robotics.jpg",title:"Clearfield Robotics",source:"2017 - MRSD Class of 2018",markdown:r},{img_name:"variable_stiffness.jpg",title:"Variable Stiffness Spring Actuators for Low-Energy-Cost Human Augmentation",source:"2019 - IEEE Transactions on Robotics",markdown:l},{img_name:"stiffness_modulator.jpg",title:"Stiffness Modulator: A Novel Actuator for Human Augmentation",source:"2018 - IEEE ICRA",markdown:c},{img_name:"analytical_design.jpg",title:"Analytical conditions for the design of variable stiffness mechanisms",source:"2017 - IEEE ICRA",markdown:d}],expanded:!1}}},u=m,h=n("2877"),p=n("9989"),f=n("eebe"),g=n.n(f),w=Object(h["a"])(u,a,i,!1,null,null,null);t["default"]=w.exports;g()(w,"components",{QPage:p["a"]})}}]);